{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7234eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to privateuseone:0\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.core.schema import NodeRelationship, RelatedNodeInfo, TextNode\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n",
    "import torch_directml\n",
    "from typing import cast\n",
    "\n",
    "TOP_K = 20\n",
    "SCORE_THRESHOLD = 0.45\n",
    "\n",
    "input_questions_path = \"data/benchmark_query_rewriting.json\"\n",
    "output_retrieved_contexts_path = f\"data/retrieved_contexts_{int(SCORE_THRESHOLD*100)}_temp.json\"\n",
    "\n",
    "device = torch_directml.device()\n",
    "\n",
    "# Load embedding model\n",
    "model_name = \"ibm-granite/granite-embedding-30m-english\"\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "embed_model._model = embed_model._model.to(device)\n",
    "print(f\"Model moved to {device}\")\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Open connection to the ElasticSearch DB where the embeddings of the documents are stored\n",
    "elastic_search_store = ElasticsearchStore(\n",
    "    index_name=\"techqa-index\",\n",
    "    es_url=\"http://localhost:9200\",\n",
    "    show_progress=True\n",
    ")\n",
    "index = VectorStoreIndex.from_vector_store(elastic_search_store)\n",
    "\n",
    "# Set up the document retriever\n",
    "retriever = index.as_retriever(similarity_top_k=TOP_K)\n",
    "\n",
    "# Open input file\n",
    "with open(input_questions_path, \"r\") as file:\n",
    "    benchmark_instances = json.load(file)\n",
    "\n",
    "\n",
    "questions_array = []\n",
    "quest_count = 0\n",
    "for benchmark_instance in benchmark_instances:\n",
    "    \n",
    "    if quest_count % 50 == 0:\n",
    "        print(str(quest_count))\n",
    "    quest_count += 1\n",
    "    \n",
    "    question = benchmark_instance[\"rewrited_question\"]\n",
    "    \n",
    "    # Split the query in multiple subqueries\n",
    "    queries = question.split(\";\")\n",
    "    \n",
    "    new_queries = []\n",
    "    for query in queries:\n",
    "        if query != \"\":\n",
    "            new_queries.append(query)\n",
    "    \n",
    "    found_ids = []\n",
    "    question_documents = []\n",
    "    \n",
    "    for query in new_queries:\n",
    "        \n",
    "        # Retrieve relevant sections\n",
    "        retrieved_sections = retriever.retrieve(query)\n",
    "        \n",
    "        for section in retrieved_sections:\n",
    "            # Retrieve all sections with a score greater than threshold\n",
    "            if section.score is not None and section.score > SCORE_THRESHOLD:\n",
    "                context_dict = {}\n",
    "                doc_id = section.metadata[\"document_id\"] \n",
    "                doc_title = section.metadata[\"document_title\"] \n",
    "                \n",
    "                # Rebuild the original document that contains the section found, avoiding duplicates\n",
    "                if doc_id not in found_ids:\n",
    "                    found_ids.append(doc_id)\n",
    "                    first_node = section.node\n",
    "                    \n",
    "                    # Get the first node (section) of the document\n",
    "                    while NodeRelationship.PREVIOUS in first_node.relationships:\n",
    "                        previous_id = cast(RelatedNodeInfo, first_node.relationships[NodeRelationship.PREVIOUS]).node_id\n",
    "                        first_node = index.vector_store.get_nodes([previous_id])[0]\n",
    "                            \n",
    "                    cur_node = first_node\n",
    "                    document = {}\n",
    "                    document[\"document_id\"] = doc_id\n",
    "                    document[\"document_title\"] = doc_title\n",
    "                    sections = []\n",
    "\n",
    "                    # Iterate all the section until the document is completely rebuilt\n",
    "                    while NodeRelationship.NEXT in cur_node.relationships:\n",
    "                        section = {}\n",
    "                        section[\"section_title\"] = cur_node.metadata[\"section_title\"]\n",
    "                        section[\"section_text\"] = cast(TextNode, cur_node).text\n",
    "                        sections.append(section)\n",
    "                        \n",
    "                        next_id = cast(RelatedNodeInfo, cur_node.relationships[NodeRelationship.NEXT]).node_id\n",
    "                        cur_node = index.vector_store.get_nodes([next_id])[0]\n",
    "                    \n",
    "                    # Get the last node (section) of the document\n",
    "                    section = {}\n",
    "                    section[\"section_title\"] = cur_node.metadata[\"section_title\"]\n",
    "                    section[\"section_text\"] = cast(TextNode, cur_node).text\n",
    "                    sections.append(section)\n",
    "\n",
    "                    document[\"sections\"] = sections  \n",
    "                    question_documents.append(document) \n",
    "                    \n",
    "    questions_array.append(question_documents)       \n",
    "\n",
    "\n",
    "# Save the retrieved documents in a json file\n",
    "with open(output_retrieved_contexts_path, \"w\") as file:\n",
    "    json.dump(questions_array, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
