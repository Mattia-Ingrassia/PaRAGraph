{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer \n",
    "\n",
    "questions_file_path = \"/kaggle/input/benchmark-techqa/benchmark.json\"\n",
    "rewrited_questions_file_path = \"/kaggle/working/benchmark_query_rewriting.json\"\n",
    "\n",
    "# Open input file\n",
    "with open(questions_file_path, \"r\") as benchmark_file:\n",
    "    benchmark_instances = json.load(benchmark_file)\n",
    "\n",
    "# Set GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Load query rewriting model\n",
    "query_rewriter_model_name = \"catyung/t5l-turbo-hotpot-0331\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(query_rewriter_model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(query_rewriter_model_name)\n",
    "\n",
    "quest_cont = 0\n",
    "new_benchmark_instances = []\n",
    "\n",
    "for benchmark_instance in benchmark_instances:\n",
    "    if quest_cont % 50 == 0:\n",
    "        print(str(quest_cont))\n",
    "    quest_cont = quest_cont + 1\n",
    "    \n",
    "    # Give a prompt to the model for rewriting the question\n",
    "    user_query = benchmark_instance[\"question\"]\n",
    "    rewrite_prompt = f\"\"\"rewrite a better search query: {user_query}\n",
    "    answer:\"\"\"\n",
    "    input_ids = tokenizer(rewrite_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
    "    rewrited_question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    new_benchmark_instance = benchmark_instance\n",
    "    new_benchmark_instance[\"rewrited_question\"] = rewrited_question\n",
    "    new_benchmark_instances.append(new_benchmark_instance)\n",
    "    \n",
    "with open(rewrited_questions_file_path, \"w\") as file:\n",
    "    json.dump(new_benchmark_instances, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
