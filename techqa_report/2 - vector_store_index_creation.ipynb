{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings, StorageContext\n",
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n",
    "import json\n",
    "import torch_directml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the GPU with DirectML (Only for not cuda GPUs, if you have cuda use torch instead)\n",
    "print(\"Torch DirectML available:\", torch_directml.is_available())\n",
    "device = torch_directml.device()\n",
    "\n",
    "input_sections_path = \"custom_sections_512.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b77475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "embedding_model_name = \"ibm-granite/granite-embedding-30m-english\"\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=embedding_model_name,\n",
    "    device=device, \n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "embed_model._model = embed_model._model.to(device)\n",
    "print(f\"Model moved to {device}\")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c421cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_counter = 0\n",
    "all_nodes = []\n",
    "with open(input_sections_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        line_documents = json.loads(line)\n",
    "        for document in line_documents:\n",
    "            document_id = document[\"id\"]\n",
    "            sections = document[\"sections\"]\n",
    "            title = document[\"title\"]\n",
    "            document_nodes = []\n",
    "\n",
    "            # Create a node for each section\n",
    "            for section in sections:\n",
    "                node = TextNode(\n",
    "                    text = section[\"text\"], \n",
    "                    metadata = {\n",
    "                        \"document_title\": title, \n",
    "                        \"document_id\": document_id, \n",
    "                        \"section_title\": section[\"title\"]\n",
    "                    }\n",
    "                )\n",
    "                document_nodes.append(node)\n",
    "            \n",
    "            # Create relationships between nodes\n",
    "            if len(document_nodes) > 1:\n",
    "                # First node \n",
    "                document_nodes[0].relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n",
    "                    node_id=document_nodes[1].node_id\n",
    "                )\n",
    "                \n",
    "                for i in range(1, len(document_nodes) - 1):\n",
    "                    document_nodes[i].relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n",
    "                        node_id=document_nodes[i + 1].node_id\n",
    "                    )\n",
    "                    document_nodes[i].relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n",
    "                        node_id=document_nodes[i - 1].node_id\n",
    "                    )\n",
    "                    \n",
    "                # Last node\n",
    "                document_nodes[-1].relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n",
    "                    node_id=document_nodes[-2].node_id\n",
    "                )\n",
    "\n",
    "            all_nodes.extend(document_nodes)\n",
    "        \n",
    "        print(f\"Line {line_counter + 1}, nodes created: {len(all_nodes)}\")\n",
    "                \n",
    "        line_counter = line_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b19b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the Database (elasticsearch) with the nodes\n",
    "\n",
    "elasticsearch_store = ElasticsearchStore(\n",
    "    index_name=\"techqa-index\",\n",
    "    es_url=\"http://localhost:9200\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=elasticsearch_store)\n",
    "index = VectorStoreIndex(all_nodes, storage_context=storage_context, show_progress=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
